{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Classifying concussion diagnosis using fMRI data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# environment\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn import metrics\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.model_selection import train_test_split, RandomizedSearchCV, learning_curve, cross_val_score, StratifiedKFold\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from imblearn.pipeline import Pipeline\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from tqdm import tqdm\n",
    "import time\n",
    "import json\n",
    "from datetime import datetime\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import plotly.io as pio\n",
    "import joblib"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Functions\n",
    "### Plotting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot confusion matrix\n",
    "def plot_confusion_matrix(y_true, y_pred, save_path=None):\n",
    "    \"\"\"\n",
    "    Plot and save confusion matrix.\n",
    "    \"\"\"\n",
    "    cm = metrics.confusion_matrix(y_true, y_pred)\n",
    "    plt.figure(figsize=(8, 6))\n",
    "    sns.heatmap(cm, annot=True, fmt='d', cmap='Blues')\n",
    "    plt.title('Confusion Matrix')\n",
    "    plt.ylabel('True Label')\n",
    "    plt.xlabel('Predicted Label')\n",
    "    \n",
    "    if save_path:\n",
    "        plt.savefig(save_path)\n",
    "        print(f\"Confusion matrix saved to {save_path}\")\n",
    "    plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot roc curve\n",
    "def plot_roc_curve(y_true, y_pred_proba, save_path=None):\n",
    "    \"\"\"\n",
    "    Plot and save ROC curve.\n",
    "    \"\"\"\n",
    "    fpr, tpr, _ = metrics.roc_curve(y_true, y_pred_proba[:, 1])\n",
    "    roc_auc = metrics.auc(fpr, tpr)\n",
    "    \n",
    "    plt.figure(figsize=(8, 6))\n",
    "    plt.plot(fpr, tpr, color='darkorange', lw=2, label=f'ROC curve (AUC = {roc_auc:.4f})')\n",
    "    plt.plot([0, 1], [0, 1], color='navy', lw=2, linestyle='--')\n",
    "    plt.xlim([0.0, 1.0])\n",
    "    plt.ylim([0.0, 1.05])\n",
    "    plt.xlabel('False Positive Rate')\n",
    "    plt.ylabel('True Positive Rate')\n",
    "    plt.title('Receiver Operating Characteristic (ROC) Curve')\n",
    "    plt.legend(loc=\"lower right\")\n",
    "    \n",
    "    if save_path:\n",
    "        plt.savefig(save_path)\n",
    "        print(f\"ROC curve saved to {save_path}\")\n",
    "    plt.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot precision recall curve\n",
    "def plot_precision_recall_curve(y_true, y_pred_proba, save_path=None):\n",
    "    \"\"\"\n",
    "    Plot and save Precision-Recall curve.\n",
    "    \"\"\"\n",
    "    precision, recall, _ = metrics.precision_recall_curve(y_true, y_pred_proba[:, 1])\n",
    "    pr_auc = metrics.auc(recall, precision)\n",
    "    \n",
    "    plt.figure(figsize=(8, 6))\n",
    "    plt.plot(recall, precision, color='darkorange', lw=2, label=f'PR curve (AUC = {pr_auc:.2f})')\n",
    "    plt.xlim([0.0, 1.0])\n",
    "    plt.ylim([0.0, 1.05])\n",
    "    plt.xlabel('Recall')\n",
    "    plt.ylabel('Precision')\n",
    "    plt.title('Precision-Recall Curve')\n",
    "    plt.legend(loc=\"lower left\")\n",
    "    \n",
    "    if save_path:\n",
    "        plt.savefig(save_path)\n",
    "        print(f\"Precision-Recall curve saved to {save_path}\")\n",
    "    plt.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot learning curves\n",
    "def plot_learning_curves(estimator, X, y, save_path=None):\n",
    "    \"\"\"\n",
    "    Plot and save learning curves.\n",
    "    \"\"\"\n",
    "    train_sizes, train_scores, val_scores = learning_curve(\n",
    "        estimator, X, y, cv=5, n_jobs=-1, \n",
    "        train_sizes=np.linspace(0.1, 1.0, 10),\n",
    "        scoring='f1'\n",
    "    )\n",
    "    \n",
    "    train_mean = np.mean(train_scores, axis=1)\n",
    "    train_std = np.std(train_scores, axis=1)\n",
    "    val_mean = np.mean(val_scores, axis=1)\n",
    "    val_std = np.std(val_scores, axis=1)\n",
    "    \n",
    "    plt.figure(figsize=(10, 6))\n",
    "    plt.plot(train_sizes, train_mean, label='Training score')\n",
    "    plt.fill_between(train_sizes, train_mean - train_std, train_mean + train_std, alpha=0.1)\n",
    "    plt.plot(train_sizes, val_mean, label='Cross-validation score')\n",
    "    plt.fill_between(train_sizes, val_mean - val_std, val_mean + val_std, alpha=0.1)\n",
    "    plt.xlabel('Training Examples')\n",
    "    plt.ylabel('F1 Score')\n",
    "    plt.title('Learning Curves')\n",
    "    plt.legend(loc='best')\n",
    "    plt.grid(True)\n",
    "    \n",
    "    if save_path:\n",
    "        plt.savefig(save_path)\n",
    "        print(f\"Learning curves saved to {save_path}\")\n",
    "    plt.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot feature importance\n",
    "def plot_feature_importance(feature_importance, feature_names, save_path=None):\n",
    "    \"\"\"\n",
    "    Plot and save feature importance.\n",
    "    \"\"\"\n",
    "    plt.figure(figsize=(12, 6))\n",
    "    importance_df = pd.DataFrame({\n",
    "        'feature': feature_names,\n",
    "        'importance': feature_importance\n",
    "    }).sort_values('importance', ascending=False)\n",
    "    \n",
    "    sns.barplot(x='importance', y='feature', data=importance_df.head(20))\n",
    "    plt.title('Top 20 Most Important Features')\n",
    "    plt.xlabel('Feature Importance')\n",
    "    plt.ylabel('Feature')\n",
    "    \n",
    "    if save_path:\n",
    "        plt.savefig(save_path)\n",
    "        print(f\"Feature importance plot saved to {save_path}\")\n",
    "    plt.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot cross-validation scores\n",
    "def plot_cv_scores(cv_scores, save_path=None):\n",
    "    \"\"\"\n",
    "    Plot and save cross-validation scores distribution.\n",
    "    \"\"\"\n",
    "    plt.figure(figsize=(8, 6))\n",
    "    sns.boxplot(x=cv_scores)\n",
    "    plt.title('Cross-validation Scores Distribution')\n",
    "    plt.xlabel('F1 Score')\n",
    "    \n",
    "    if save_path:\n",
    "        plt.savefig(save_path)\n",
    "        print(f\"CV scores distribution saved to {save_path}\")\n",
    "    plt.close()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data prep"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data loading\n",
    "def load_data(data_file):\n",
    "    '''\n",
    "    load_data()\n",
    "\n",
    "    Loads data from CSV file.\n",
    "    \n",
    "    --------\n",
    "    Args:\n",
    "\n",
    "    data_file: (Type: String) Name of CSV file containing data\n",
    "    --------\n",
    "    Returns:\n",
    "\n",
    "    features: (Type: numpy.ndarray) Features of the dataset.\n",
    "    labels: (Type: numpy.ndarray) Labels of the dataset\n",
    "    feature_names: (Type: list) Names of the features\n",
    "    '''\n",
    "    print(f\"Loading data from {data_file}...\")\n",
    "    df = pd.read_csv(data_file)\n",
    "    # extract feature names from the first row\n",
    "    feature_names = df.columns.tolist()[1:]  # Skip the 'Label' column\n",
    "    print(f\"\\nFeature names: {feature_names[:5]}... (total: {len(feature_names)} features)\")\n",
    "    \n",
    "    # first column is the target variable, features are all other columns\n",
    "    y = df.iloc[:, 0].values    \n",
    "    X = df.iloc[:, 1:].values   \n",
    "    \n",
    "    print(f\"Loaded {X.shape[0]} samples with {X.shape[1]} features\")\n",
    "    print(\"Class distribution before SMOTE:\")\n",
    "    unique, counts = np.unique(y, return_counts=True)\n",
    "    for label, count in zip(unique, counts):\n",
    "        print(f\"Class {label}: {count} samples\")\n",
    "    \n",
    "    return X, y, feature_names\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# saving model parameters\n",
    "def save_results(results, filename=None):\n",
    "    '''\n",
    "    Save model results to a JSON file.\n",
    "    \n",
    "    --------\n",
    "    Args:\n",
    "    results: (Type: dict) Dictionary containing model results\n",
    "    filename: (Type: str) Optional filename, defaults to timestamp\n",
    "    '''\n",
    "    if filename is None:\n",
    "        timestamp = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "        filename = f\"model_results_{timestamp}.json\"\n",
    "    \n",
    "    with open(filename, 'w') as f:\n",
    "        json.dump(results, f, indent=4)\n",
    "    print(f\"Results saved to {filename}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# main pipeline\n",
    "def main(file):\n",
    "    start_time = time.time()\n",
    "    # set random seed for reproducibility\n",
    "    np.random.seed(89)\n",
    "\n",
    "    # load data\n",
    "    X, y, feature_names = load_data(file)\n",
    "\n",
    "    # train test splits\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=89, stratify=y)\n",
    "    print(f\"\\nTraining set size: {X_train.shape[0]}, Test set size: {X_test.shape[0]}\")\n",
    "\n",
    "    # check minority class in training set\n",
    "    minority_class_count = np.sum(y_train == 1)\n",
    "    print(f\"Number of minority class samples in training set: {minority_class_count}\")\n",
    "    \n",
    "    # determine a safe k_neighbors value for SMOTE\n",
    "    # ensuring k_neighbors is less than the number of minority class samples\n",
    "    safe_k = max(1, min(3, minority_class_count - 1))\n",
    "    print(f\"Using k_neighbors={safe_k} for SMOTE to avoid errors\")\n",
    "\n",
    "    # pipeline with SMOTE\n",
    "    pipeline = Pipeline([\n",
    "        ('scaler', StandardScaler()),\n",
    "        ('smote', SMOTE(random_state=89, k_neighbors=safe_k, sampling_strategy='auto')),\n",
    "        ('classifier', GradientBoostingClassifier(random_state=89))\n",
    "    ])\n",
    "\n",
    "    # define parameter distributions for randomizedsearchcv\n",
    "    # add regularization parameters to reduce overfitting\n",
    "    param_distributions = {\n",
    "        'smote__k_neighbors': [1, 2, 3],\n",
    "        'classifier__n_estimators': [100, 200, 300, 400, 500],\n",
    "        'classifier__learning_rate': [0.001, 0.01, 0.05, 0.1, 0.2],\n",
    "        'classifier__max_depth': [2, 3, 4],\n",
    "        'classifier__min_samples_split': [2, 5, 10, 15, 20],\n",
    "        'classifier__min_samples_leaf': [2, 4, 6, 8],\n",
    "        'classifier__subsample': [0.6, 0.7, 0.8, 0.9, 1.0],\n",
    "        'classifier__max_features': ['sqrt', 'log2', None]\n",
    "    }\n",
    "\n",
    "    # create randomizedsearchcv object with stratification\n",
    "    random_search = RandomizedSearchCV(\n",
    "        pipeline,\n",
    "        param_distributions,\n",
    "        n_iter=50, \n",
    "        cv=StratifiedKFold(n_splits=3, shuffle=True, random_state=89),  \n",
    "        scoring='f1',\n",
    "        n_jobs=-1,\n",
    "        verbose=1,\n",
    "        random_state=42,\n",
    "        error_score='raise'\n",
    "    )\n",
    "\n",
    "    # fit randomizedsearchcv\n",
    "    print(\"\\nStarting RandomizedSearchCV...\")\n",
    "    with tqdm(total=100, desc=\"Training Progress\") as pbar:\n",
    "        random_search.fit(X_train, y_train)\n",
    "        pbar.update(100)\n",
    "\n",
    "    # cross-validation scores\n",
    "    cv = StratifiedKFold(n_splits=3, shuffle=True, random_state=89)\n",
    "    cv_scores = cross_val_score(random_search.best_estimator_, X_train, y_train, cv=cv, scoring='f1')\n",
    "    print(f\"\\nCross-validation scores: {cv_scores}\")\n",
    "    print(f\"Mean CV score: {cv_scores.mean():.3f} (+/- {cv_scores.std() * 2:.3f})\")\n",
    "\n",
    "    # resampled training data for visualization\n",
    "    best_pipeline = random_search.best_estimator_\n",
    "    X_train_resampled, y_train_resampled = best_pipeline.named_steps['smote'].fit_resample(\n",
    "        best_pipeline.named_steps['scaler'].fit_transform(X_train), \n",
    "        y_train\n",
    "    )\n",
    "\n",
    "    # collect results\n",
    "    results = {\n",
    "        'best_parameters': random_search.best_params_,\n",
    "        'best_cv_score': float(random_search.best_score_),\n",
    "        'cv_scores': cv_scores.tolist(),\n",
    "        'training_time': time.time() - start_time,\n",
    "        'n_samples': X.shape[0],\n",
    "        'n_features': X.shape[1],\n",
    "        'class_distribution_before': {str(k): int(v) for k, v in zip(*np.unique(y, return_counts=True))},\n",
    "        'class_distribution_after_smote': {str(k): int(v) for k, v in zip(*np.unique(y_train_resampled, return_counts=True))},\n",
    "        'best_k_neighbors': random_search.best_params_['smote__k_neighbors']\n",
    "    }\n",
    "\n",
    "    # get best model\n",
    "    best_model = random_search.best_estimator_\n",
    "\n",
    "    # test metrics\n",
    "    y_pred = best_model.predict(X_test)\n",
    "    y_pred_proba = best_model.predict_proba(X_test)\n",
    "    \n",
    "    # additional metrics\n",
    "    results['test_accuracy'] = float(metrics.accuracy_score(y_test, y_pred))\n",
    "    results['test_auc'] = float(metrics.roc_auc_score(y_test, y_pred_proba[:, 1]))\n",
    "    results['test_f1'] = float(metrics.f1_score(y_test, y_pred))\n",
    "    results['test_precision'] = float(metrics.precision_score(y_test, y_pred))\n",
    "    results['test_recall'] = float(metrics.recall_score(y_test, y_pred))\n",
    "    results['classification_report'] = metrics.classification_report(y_test, y_pred, output_dict=True)\n",
    "\n",
    "    # print results\n",
    "    print(\"\\n=== Model Performance ===\")\n",
    "    print(f\"Best parameters: {results['best_parameters']}\")\n",
    "    print(f\"Best CV score: {results['best_cv_score']:.4f}\")\n",
    "    print(f\"Test accuracy: {results['test_accuracy']:.4f}\")\n",
    "    print(f\"Test AUC: {results['test_auc']:.4f}\")\n",
    "    print(f\"Test F1-score: {results['test_f1']:.4f}\")\n",
    "    print(f\"Test Precision: {results['test_precision']:.4f}\")\n",
    "    print(f\"Test Recall: {results['test_recall']:.4f}\")\n",
    "    print(f\"\\nTraining time: {results['training_time']:.2f} seconds\")\n",
    "\n",
    "    # generate and save visualizations\n",
    "    timestamp = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "    plot_confusion_matrix(y_test, y_pred, f'confusion_matrix_{timestamp}.png')\n",
    "    plot_roc_curve(y_test, y_pred_proba, f'roc_curve_{timestamp}.png')\n",
    "    plot_precision_recall_curve(y_test, y_pred_proba, f'precision_recall_curve_{timestamp}.png')\n",
    "    plot_learning_curves(best_model, X_train, y_train, f'learning_curves_{timestamp}.png')\n",
    "    plot_cv_scores(cv_scores, f'cv_scores_{timestamp}.png')\n",
    "    \n",
    "    # get feature importance\n",
    "    feature_importance = best_model.named_steps['classifier'].feature_importances_\n",
    "    plot_feature_importance(feature_importance, feature_names, f'feature_importance_{timestamp}.png')\n",
    "    \n",
    "    features_rank = pd.Series(feature_importance, index=feature_names).sort_values(ascending=False)\n",
    "    print(\"\\n=== Top 10 Most Important Features ===\")\n",
    "    print(features_rank.head(400))\n",
    "\n",
    "    # save results\n",
    "    save_results(results)\n",
    "\n",
    "    return best_model, feature_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading data from synthetic_data.csv...\n",
      "\n",
      "Feature names: ['FP_r_Metric01', 'FP_l_Metric01', 'IC_r_Metric01', 'IC_l_Metric01', 'SFG_r_Metric01']... (total: 792 features)\n",
      "Loaded 400 samples with 792 features\n",
      "Class distribution before SMOTE:\n",
      "Class 0: 372 samples\n",
      "Class 1: 28 samples\n",
      "\n",
      "Training set size: 320, Test set size: 80\n",
      "Number of minority class samples in training set: 22\n",
      "Using k_neighbors=3 for SMOTE to avoid errors\n",
      "\n",
      "Starting RandomizedSearchCV...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Progress:   0%|          | 0/100 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 50 candidates, totalling 150 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Progress: 100%|██████████| 100/100 [01:13<00:00,  1.35it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Cross-validation scores: [0.55555556 0.4        0.36363636]\n",
      "Mean CV score: 0.440 (+/- 0.166)\n",
      "\n",
      "=== Model Performance ===\n",
      "Best parameters: {'smote__k_neighbors': 3, 'classifier__subsample': 0.7, 'classifier__n_estimators': 300, 'classifier__min_samples_split': 5, 'classifier__min_samples_leaf': 6, 'classifier__max_features': 'sqrt', 'classifier__max_depth': 2, 'classifier__learning_rate': 0.001}\n",
      "Best CV score: 0.4397\n",
      "Test accuracy: 0.9250\n",
      "Test AUC: 0.9505\n",
      "Test F1-score: 0.6667\n",
      "Test Precision: 0.5000\n",
      "Test Recall: 1.0000\n",
      "\n",
      "Training time: 75.54 seconds\n",
      "Confusion matrix saved to confusion_matrix_20250622_111612.png\n",
      "ROC curve saved to roc_curve_20250622_111612.png\n",
      "Precision-Recall curve saved to precision_recall_curve_20250622_111612.png\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\sharm\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py:528: FitFailedWarning: \n",
      "5 fits failed out of a total of 50.\n",
      "The score on these train-test partitions for these parameters will be set to nan.\n",
      "If these failures are not expected, you can try to debug them by setting error_score='raise'.\n",
      "\n",
      "Below are more details about the failures:\n",
      "--------------------------------------------------------------------------------\n",
      "1 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\sharm\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 866, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "    ~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\sharm\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\sklearn\\base.py\", line 1389, in wrapper\n",
      "    return fit_method(estimator, *args, **kwargs)\n",
      "  File \"c:\\Users\\sharm\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\imblearn\\pipeline.py\", line 518, in fit\n",
      "    Xt, yt = self._fit(X, y, routed_params, raw_params=params)\n",
      "             ~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\sharm\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\imblearn\\pipeline.py\", line 440, in _fit\n",
      "    X, y, fitted_transformer = fit_resample_one_cached(\n",
      "                               ~~~~~~~~~~~~~~~~~~~~~~~^\n",
      "        cloned_transformer,\n",
      "        ^^^^^^^^^^^^^^^^^^^\n",
      "    ...<4 lines>...\n",
      "        params=routed_params[name],\n",
      "        ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "    )\n",
      "    ^\n",
      "  File \"c:\\Users\\sharm\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\joblib\\memory.py\", line 326, in __call__\n",
      "    return self.func(*args, **kwargs)\n",
      "           ~~~~~~~~~^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\sharm\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\imblearn\\pipeline.py\", line 1336, in _fit_resample_one\n",
      "    X_res, y_res = sampler.fit_resample(X, y, **params.get(\"fit_resample\", {}))\n",
      "                   ~~~~~~~~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\sharm\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\imblearn\\base.py\", line 202, in fit_resample\n",
      "    return super().fit_resample(X, y, **params)\n",
      "           ~~~~~~~~~~~~~~~~~~~~^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\sharm\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\sklearn\\base.py\", line 1389, in wrapper\n",
      "    return fit_method(estimator, *args, **kwargs)\n",
      "  File \"c:\\Users\\sharm\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\imblearn\\base.py\", line 105, in fit_resample\n",
      "    output = self._fit_resample(X, y, **params)\n",
      "  File \"c:\\Users\\sharm\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\imblearn\\over_sampling\\_smote\\base.py\", line 359, in _fit_resample\n",
      "    nns = self.nn_k_.kneighbors(X_class, return_distance=False)[:, 1:]\n",
      "          ~~~~~~~~~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\sharm\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\sklearn\\neighbors\\_base.py\", line 854, in kneighbors\n",
      "    raise ValueError(\n",
      "    ...<3 lines>...\n",
      "    )\n",
      "ValueError: Expected n_neighbors <= n_samples_fit, but n_neighbors = 4, n_samples_fit = 3, n_samples = 3\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "4 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\sharm\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 866, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "    ~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\sharm\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\sklearn\\base.py\", line 1389, in wrapper\n",
      "    return fit_method(estimator, *args, **kwargs)\n",
      "  File \"c:\\Users\\sharm\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\imblearn\\pipeline.py\", line 518, in fit\n",
      "    Xt, yt = self._fit(X, y, routed_params, raw_params=params)\n",
      "             ~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\sharm\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\imblearn\\pipeline.py\", line 440, in _fit\n",
      "    X, y, fitted_transformer = fit_resample_one_cached(\n",
      "                               ~~~~~~~~~~~~~~~~~~~~~~~^\n",
      "        cloned_transformer,\n",
      "        ^^^^^^^^^^^^^^^^^^^\n",
      "    ...<4 lines>...\n",
      "        params=routed_params[name],\n",
      "        ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "    )\n",
      "    ^\n",
      "  File \"c:\\Users\\sharm\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\joblib\\memory.py\", line 326, in __call__\n",
      "    return self.func(*args, **kwargs)\n",
      "           ~~~~~~~~~^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\sharm\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\imblearn\\pipeline.py\", line 1336, in _fit_resample_one\n",
      "    X_res, y_res = sampler.fit_resample(X, y, **params.get(\"fit_resample\", {}))\n",
      "                   ~~~~~~~~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\sharm\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\imblearn\\base.py\", line 202, in fit_resample\n",
      "    return super().fit_resample(X, y, **params)\n",
      "           ~~~~~~~~~~~~~~~~~~~~^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\sharm\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\sklearn\\base.py\", line 1389, in wrapper\n",
      "    return fit_method(estimator, *args, **kwargs)\n",
      "  File \"c:\\Users\\sharm\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\imblearn\\base.py\", line 105, in fit_resample\n",
      "    output = self._fit_resample(X, y, **params)\n",
      "  File \"c:\\Users\\sharm\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\imblearn\\over_sampling\\_smote\\base.py\", line 359, in _fit_resample\n",
      "    nns = self.nn_k_.kneighbors(X_class, return_distance=False)[:, 1:]\n",
      "          ~~~~~~~~~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\sharm\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\sklearn\\neighbors\\_base.py\", line 854, in kneighbors\n",
      "    raise ValueError(\n",
      "    ...<3 lines>...\n",
      "    )\n",
      "ValueError: Expected n_neighbors <= n_samples_fit, but n_neighbors = 4, n_samples_fit = 2, n_samples = 2\n",
      "\n",
      "  warnings.warn(some_fits_failed_message, FitFailedWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Learning curves saved to learning_curves_20250622_111612.png\n",
      "CV scores distribution saved to cv_scores_20250622_111612.png\n",
      "Feature importance plot saved to feature_importance_20250622_111612.png\n",
      "\n",
      "=== Top 10 Most Important Features ===\n",
      "CO_l_Metric05        0.039635\n",
      "Ver12_Metric01       0.039480\n",
      "Ver12_Metric02       0.038301\n",
      "aTFusC_r_Metric05    0.036173\n",
      "Ver10_Metric01       0.029938\n",
      "                       ...   \n",
      "PostCG_r_Metric03    0.000000\n",
      "FP_r_Metric04        0.000000\n",
      "FP_l_Metric04        0.000000\n",
      "IC_r_Metric04        0.000000\n",
      "IC_l_Metric04        0.000000\n",
      "Length: 400, dtype: float64\n",
      "Results saved to model_results_20250622_111614.json\n"
     ]
    }
   ],
   "source": [
    "# run main() and store the returned values\n",
    "best_model, feature_names = main(\"synthetic_data.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading data from synthetic_data.csv...\n",
      "\n",
      "Feature names: ['FP_r_Metric01', 'FP_l_Metric01', 'IC_r_Metric01', 'IC_l_Metric01', 'SFG_r_Metric01']... (total: 792 features)\n",
      "Loaded 400 samples with 792 features\n",
      "Class distribution before SMOTE:\n",
      "Class 0: 372 samples\n",
      "Class 1: 28 samples\n",
      "✅ Model and data splits saved.\n"
     ]
    }
   ],
   "source": [
    "# re-run your split if these variables aren't already defined\n",
    "if 'X_train' not in globals():\n",
    "    X, y, feature_names = load_data(\"synthetic_data.csv\")\n",
    "    from sklearn.model_selection import train_test_split\n",
    "    X_train, X_test, y_train, y_test = train_test_split(\n",
    "        X, y, test_size=0.2, random_state=89, stratify=y\n",
    "    )\n",
    "\n",
    "# save model and splits\n",
    "os.makedirs(\"data\", exist_ok=True)\n",
    "joblib.dump(best_model, \"best_model.pkl\")\n",
    "joblib.dump((X_train, X_test, y_train, y_test), \"data/splits.pkl\")\n",
    "\n",
    "print(\"✅ Model and data splits saved.\") "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
